{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Problem 3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"id":"1-nestcDKHQT"},"source":["import numpy\n","import sys\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, LSTM\n","from keras.utils import np_utils\n","from keras.callbacks import ModelCheckpoint\n","# import io\n","# from keras.utils.data_utils import get_file\n","# import keras"],"execution_count":52,"outputs":[]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["file = open(\"text.txt\").read()\n","file=file.lower()"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["chars = sorted(list(set(file)))\n","char_to_num = dict((c, i) for i, c in enumerate(chars))"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of characters: 581887\nTotal vocab: 72\n"]}],"source":["input_len = len(file)\n","vocab_len = len(chars)\n","print (\"Number of characters:\", input_len)\n","print (\"Total vocab:\", vocab_len)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["seq_length = 100\n","x_data = []\n","y_data = []"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["for i in range(0, input_len - seq_length, 1):\n","    # Define input and output sequences\n","    # Input is the current character plus desired sequence length\n","    in_seq = file[i:i + seq_length]\n","\n","    # Out sequence is the initial character plus total sequence length\n","    out_seq = file[i + seq_length]\n","\n","    # We now convert list of characters to integers based on\n","    # previously and add the values to our lists\n","    x_data.append([char_to_num[char] for char in in_seq])\n","    y_data.append(char_to_num[out_seq])"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Total Patterns: 581787\n"]}],"source":["n_patterns = len(x_data)\n","print (\"Number of Patterns:\", n_patterns)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n","X = X/float(vocab_len)"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["y = np_utils.to_categorical(y_data)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["model = Sequential()\n","model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(256, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(128))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.fit(X, y, epochs=20, batch_size=256)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_to_char = dict((i, c) for i, c in enumerate(chars))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["start = numpy.random.randint(0, len(x_data) - 1)\n","pattern = x_data[start]\n","print(\"Random set:\")\n","print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(1000):\n","    x = numpy.reshape(pattern, (1, len(pattern), 1))\n","    x = x / float(vocab_len)\n","    prediction = model.predict(x, verbose=0)\n","    index = numpy.argmax(prediction)\n","    result = num_to_char[index]\n","\n","    sys.stdout.write(result)\n","\n","    pattern.append(index)\n","    pattern = pattern[1:len(pattern)]"]}]}